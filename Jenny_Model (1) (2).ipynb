{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3222c17d-c52b-4299-a9b4-447d624ec4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ac8bc-aec3-44b9-9969-c30e832761a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18ee7a1-01c0-48ad-baf4-f7ceedf77780",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datasets transformers pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf75d182-f1a4-47cb-b08f-c6fc7b1dfcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e2fd0-4827-49b8-80ab-77901c08fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b8abca3-bca3-4ec2-bfff-10bdd8782016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e392e662-2c28-44a2-8ebe-3a01b83354df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#laod the dataset \n",
    "with open('documents_with_descriptions.json', 'r') as file:\n",
    "    raw_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98cc1c4-1241-4218-8cd1-19de24322d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "051d963b-5e2b-49aa-aa2b-6eb5cdcf2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"input\": [\n",
    "         f\"Create a CWL pipeline for {entry['metadata'].get('description', 'an unspecified task')} using {entry['metadata'].get('baseCommand', 'a specific tool')}\"\n",
    "        for entry in raw_data\n",
    "    ],\n",
    "    \"target_text\": [entry['page_content'] for entry in raw_data]\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43150092-fcf4-4b3b-b0e5-da1b44228557",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a248fe45-b0f2-4af6-ab36-132d3c59a987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7adf54aed47e44d68670bf6759f1aeff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ae6535341444a99fa1864fe0fbb1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46a2f81e0de4e908e027a1dc192c15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4bd1361967346d4a84873994646dd67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a64ba58a1047d19baa0f6a7a191c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fd7fcd9-bb6d-4f96-920c-8f8f4b289804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alternative_description(desc):\n",
    "    # Preprocess the CWL content\n",
    "    cwl_summary_prompt = f\"Create a cwl pipeline:\\n{desc}\"\n",
    "    \n",
    "    # Encode the CWL content\n",
    "    input_ids = tokenizer.encode(cwl_summary_prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # Generate the description\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=150,\n",
    "        num_beams=5,\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_return_sequences=1,\n",
    "        temperature=0.7,  # Balance randomness and coherence\n",
    "        top_k=50,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    \n",
    "    # Decode the output\n",
    "    alternative_description = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return alternative_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39304cb5-7aa7-4b76-9608-a292f5adc63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "783\n",
      "782\n",
      "781\n",
      "780\n",
      "779\n",
      "778\n",
      "777\n",
      "776\n",
      "775\n",
      "774\n",
      "773\n",
      "772\n",
      "771\n",
      "770\n",
      "769\n",
      "768\n",
      "767\n",
      "766\n",
      "765\n",
      "764\n",
      "763\n",
      "762\n",
      "761\n",
      "760\n",
      "759\n",
      "758\n",
      "757\n",
      "756\n",
      "755\n",
      "754\n",
      "753\n",
      "752\n",
      "751\n",
      "750\n",
      "749\n",
      "748\n",
      "747\n",
      "746\n",
      "745\n",
      "744\n",
      "743\n",
      "742\n",
      "741\n",
      "740\n",
      "739\n",
      "738\n",
      "737\n",
      "736\n",
      "735\n",
      "734\n",
      "733\n",
      "732\n",
      "731\n",
      "730\n",
      "729\n",
      "728\n",
      "727\n",
      "726\n",
      "725\n",
      "724\n",
      "723\n",
      "722\n",
      "721\n",
      "720\n",
      "719\n",
      "718\n",
      "717\n",
      "716\n",
      "715\n",
      "714\n",
      "713\n",
      "712\n",
      "711\n",
      "710\n",
      "709\n",
      "708\n",
      "707\n",
      "706\n",
      "705\n",
      "704\n",
      "703\n",
      "702\n",
      "701\n",
      "700\n",
      "699\n",
      "698\n",
      "697\n",
      "696\n",
      "695\n",
      "694\n",
      "693\n",
      "692\n",
      "691\n",
      "690\n",
      "689\n",
      "688\n",
      "687\n",
      "686\n",
      "685\n",
      "684\n",
      "683\n",
      "682\n",
      "681\n",
      "680\n",
      "679\n",
      "678\n",
      "677\n",
      "676\n",
      "675\n",
      "674\n",
      "673\n",
      "672\n",
      "671\n",
      "670\n",
      "669\n",
      "668\n",
      "667\n",
      "666\n",
      "665\n",
      "664\n",
      "663\n",
      "662\n",
      "661\n",
      "660\n",
      "659\n",
      "658\n",
      "657\n",
      "656\n",
      "655\n",
      "654\n",
      "653\n",
      "652\n",
      "651\n",
      "650\n",
      "649\n",
      "648\n",
      "647\n",
      "646\n",
      "645\n",
      "644\n",
      "643\n",
      "642\n",
      "641\n",
      "640\n",
      "639\n",
      "638\n",
      "637\n",
      "636\n",
      "635\n",
      "634\n",
      "633\n",
      "632\n",
      "631\n",
      "630\n",
      "629\n",
      "628\n",
      "627\n",
      "626\n",
      "625\n",
      "624\n",
      "623\n",
      "622\n",
      "621\n",
      "620\n",
      "619\n",
      "618\n",
      "617\n",
      "616\n",
      "615\n",
      "614\n",
      "613\n",
      "612\n",
      "611\n",
      "610\n",
      "609\n",
      "608\n",
      "607\n",
      "606\n",
      "605\n",
      "604\n",
      "603\n",
      "602\n",
      "601\n",
      "600\n",
      "599\n",
      "598\n",
      "597\n",
      "596\n",
      "595\n",
      "594\n",
      "593\n",
      "592\n",
      "591\n",
      "590\n",
      "589\n",
      "588\n",
      "587\n",
      "586\n",
      "585\n",
      "584\n",
      "583\n",
      "582\n",
      "581\n",
      "580\n",
      "579\n",
      "578\n",
      "577\n",
      "576\n",
      "575\n",
      "574\n",
      "573\n",
      "572\n",
      "571\n",
      "570\n",
      "569\n",
      "568\n",
      "567\n",
      "566\n",
      "565\n",
      "564\n",
      "563\n",
      "562\n",
      "561\n",
      "560\n",
      "559\n",
      "558\n",
      "557\n",
      "556\n",
      "555\n",
      "554\n",
      "553\n",
      "552\n",
      "551\n",
      "550\n",
      "549\n",
      "548\n",
      "547\n",
      "546\n",
      "545\n",
      "544\n",
      "543\n",
      "542\n",
      "541\n",
      "540\n",
      "539\n",
      "538\n",
      "537\n",
      "536\n",
      "535\n",
      "534\n",
      "533\n",
      "532\n",
      "531\n",
      "530\n",
      "529\n",
      "528\n",
      "527\n",
      "526\n",
      "525\n",
      "524\n",
      "523\n",
      "522\n",
      "521\n",
      "520\n",
      "519\n",
      "518\n",
      "517\n",
      "516\n",
      "515\n",
      "514\n",
      "513\n",
      "512\n",
      "511\n",
      "510\n",
      "509\n",
      "508\n",
      "507\n",
      "506\n",
      "505\n",
      "504\n",
      "503\n",
      "502\n",
      "501\n",
      "500\n",
      "499\n",
      "498\n",
      "497\n",
      "496\n",
      "495\n",
      "494\n",
      "493\n",
      "492\n",
      "491\n",
      "490\n",
      "489\n",
      "488\n",
      "487\n",
      "486\n",
      "485\n",
      "484\n",
      "483\n",
      "482\n",
      "481\n",
      "480\n",
      "479\n",
      "478\n",
      "477\n",
      "476\n",
      "475\n",
      "474\n",
      "473\n",
      "472\n",
      "471\n",
      "470\n",
      "469\n",
      "468\n",
      "467\n",
      "466\n",
      "465\n",
      "464\n",
      "463\n",
      "462\n",
      "461\n",
      "460\n",
      "459\n",
      "458\n",
      "457\n",
      "456\n",
      "455\n",
      "454\n",
      "453\n",
      "452\n",
      "451\n",
      "450\n",
      "449\n",
      "448\n",
      "447\n",
      "446\n",
      "445\n",
      "444\n",
      "443\n",
      "442\n",
      "441\n",
      "440\n",
      "439\n",
      "438\n",
      "437\n",
      "436\n",
      "435\n",
      "434\n",
      "433\n",
      "432\n",
      "431\n",
      "430\n",
      "429\n",
      "428\n",
      "427\n",
      "426\n",
      "425\n",
      "424\n",
      "423\n",
      "422\n",
      "421\n",
      "420\n",
      "419\n",
      "418\n",
      "417\n",
      "416\n",
      "415\n",
      "414\n",
      "413\n",
      "412\n",
      "411\n",
      "410\n",
      "409\n",
      "408\n",
      "407\n",
      "406\n",
      "405\n",
      "404\n",
      "403\n",
      "402\n",
      "401\n",
      "400\n",
      "399\n",
      "398\n",
      "397\n",
      "396\n",
      "395\n",
      "394\n",
      "393\n",
      "392\n",
      "391\n",
      "390\n",
      "389\n",
      "388\n",
      "387\n",
      "386\n",
      "385\n",
      "384\n",
      "383\n",
      "382\n",
      "381\n",
      "380\n",
      "379\n",
      "378\n",
      "377\n",
      "376\n",
      "375\n",
      "374\n",
      "373\n",
      "372\n",
      "371\n",
      "370\n",
      "369\n",
      "368\n",
      "367\n",
      "366\n",
      "365\n",
      "364\n",
      "363\n",
      "362\n",
      "361\n",
      "360\n",
      "359\n",
      "358\n",
      "357\n",
      "356\n",
      "355\n",
      "354\n",
      "353\n",
      "352\n",
      "351\n",
      "350\n",
      "349\n",
      "348\n",
      "347\n",
      "346\n",
      "345\n",
      "344\n",
      "343\n",
      "342\n",
      "341\n",
      "340\n",
      "339\n",
      "338\n",
      "337\n",
      "336\n",
      "335\n",
      "334\n",
      "333\n",
      "332\n",
      "331\n",
      "330\n",
      "329\n",
      "328\n",
      "327\n",
      "326\n",
      "325\n",
      "324\n",
      "323\n",
      "322\n",
      "321\n",
      "320\n",
      "319\n",
      "318\n",
      "317\n",
      "316\n",
      "315\n",
      "314\n",
      "313\n",
      "312\n",
      "311\n",
      "310\n",
      "309\n",
      "308\n",
      "307\n",
      "306\n",
      "305\n",
      "304\n",
      "303\n",
      "302\n",
      "301\n",
      "300\n",
      "299\n",
      "298\n",
      "297\n",
      "296\n",
      "295\n",
      "294\n",
      "293\n",
      "292\n",
      "291\n",
      "290\n",
      "289\n",
      "288\n",
      "287\n",
      "286\n",
      "285\n",
      "284\n",
      "283\n",
      "282\n",
      "281\n",
      "280\n",
      "279\n",
      "278\n",
      "277\n",
      "276\n",
      "275\n",
      "274\n",
      "273\n",
      "272\n",
      "271\n",
      "270\n",
      "269\n",
      "268\n",
      "267\n",
      "266\n",
      "265\n",
      "264\n",
      "263\n",
      "262\n",
      "261\n",
      "260\n",
      "259\n",
      "258\n",
      "257\n",
      "256\n",
      "255\n",
      "254\n",
      "253\n",
      "252\n",
      "251\n",
      "250\n",
      "249\n",
      "248\n",
      "247\n",
      "246\n",
      "245\n",
      "244\n",
      "243\n",
      "242\n",
      "241\n",
      "240\n",
      "239\n",
      "238\n",
      "237\n",
      "236\n",
      "235\n",
      "234\n",
      "233\n",
      "232\n",
      "231\n",
      "230\n",
      "229\n",
      "228\n",
      "227\n",
      "226\n",
      "225\n",
      "224\n",
      "223\n",
      "222\n",
      "221\n",
      "220\n",
      "219\n",
      "218\n",
      "217\n",
      "216\n",
      "215\n",
      "214\n",
      "213\n",
      "212\n",
      "211\n",
      "210\n",
      "209\n",
      "208\n",
      "207\n",
      "206\n",
      "205\n",
      "204\n",
      "203\n",
      "202\n",
      "201\n",
      "200\n",
      "199\n",
      "198\n",
      "197\n",
      "196\n",
      "195\n",
      "194\n",
      "193\n",
      "192\n",
      "191\n",
      "190\n",
      "189\n",
      "188\n",
      "187\n",
      "186\n",
      "185\n",
      "184\n",
      "183\n",
      "182\n",
      "181\n",
      "180\n",
      "179\n",
      "178\n",
      "177\n",
      "176\n",
      "175\n",
      "174\n",
      "173\n",
      "172\n",
      "171\n",
      "170\n",
      "169\n",
      "168\n",
      "167\n",
      "166\n",
      "165\n",
      "164\n",
      "163\n",
      "162\n",
      "161\n",
      "160\n",
      "159\n",
      "158\n",
      "157\n",
      "156\n",
      "155\n",
      "154\n",
      "153\n",
      "152\n",
      "151\n",
      "150\n",
      "149\n",
      "148\n",
      "147\n",
      "146\n",
      "145\n",
      "144\n",
      "143\n",
      "142\n",
      "141\n",
      "140\n",
      "139\n",
      "138\n",
      "137\n",
      "136\n",
      "135\n",
      "134\n",
      "133\n",
      "132\n",
      "131\n",
      "130\n",
      "129\n",
      "128\n",
      "127\n",
      "126\n",
      "125\n",
      "124\n",
      "123\n",
      "122\n",
      "121\n",
      "120\n",
      "119\n",
      "118\n",
      "117\n",
      "116\n",
      "115\n",
      "114\n",
      "113\n",
      "112\n",
      "111\n",
      "110\n",
      "109\n",
      "108\n",
      "107\n",
      "106\n",
      "105\n",
      "104\n",
      "103\n",
      "102\n",
      "101\n",
      "100\n",
      "99\n",
      "98\n",
      "97\n",
      "96\n",
      "95\n",
      "94\n",
      "93\n",
      "92\n",
      "91\n",
      "90\n",
      "89\n",
      "88\n",
      "87\n",
      "86\n",
      "85\n",
      "84\n",
      "83\n",
      "82\n",
      "81\n",
      "80\n",
      "79\n",
      "78\n",
      "77\n",
      "76\n",
      "75\n",
      "74\n",
      "73\n",
      "72\n",
      "71\n",
      "70\n",
      "69\n",
      "68\n",
      "67\n",
      "66\n",
      "65\n",
      "64\n",
      "63\n",
      "62\n",
      "61\n",
      "60\n",
      "59\n",
      "58\n",
      "57\n",
      "56\n",
      "55\n",
      "54\n",
      "53\n",
      "52\n",
      "51\n",
      "50\n",
      "49\n",
      "48\n",
      "47\n",
      "46\n",
      "45\n",
      "44\n",
      "43\n",
      "42\n",
      "41\n",
      "40\n",
      "39\n",
      "38\n",
      "37\n",
      "36\n",
      "35\n",
      "34\n",
      "33\n",
      "32\n",
      "31\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expanded_data = []\n",
    "\n",
    "# Loop through your raw data and generate multiple descriptions for each target_text\n",
    "n = len(raw_data)\n",
    "print(n)\n",
    "for entry in raw_data:\n",
    "    target_text = entry['page_content']\n",
    "    descriptions = generate_alternative_description(entry['metadata'].get('description'))  # Generate 5 variations per target_text\n",
    "\n",
    "    # Create a list of (input, target_text) pairs for each target_text\n",
    "    group = {\"input\": descriptions, \"target_text\": target_text}\n",
    "    \n",
    "    # Append the group to the expanded data\n",
    "    expanded_data.append(group)\n",
    "    n = n -1 \n",
    "    print(n)\n",
    "    \n",
    "\n",
    "# Example output: View the first group\n",
    "print(expanded_data)  # Print the first group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef32a5-67bf-436f-97f2-d56c6bd5773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(expanded_data[0]['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e119405-8054-415e-b480-b685055ed1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e99b43c6-b4ca-4590-9a60-2254cf73ba07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "print(len(expanded_data))\n",
    "for i in range(len(expanded_data)):\n",
    "    data['input'].append(expanded_data[i]['input'])\n",
    "    data['target_text'].append(expanded_data[i]['target_text'])\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364bb1dd-d92b-40ce-be6e-0621e60382f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data['input'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9085e222-eb76-42a3-86f5-301285e55dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for text in data['target_text']:\n",
    "    l = 0\n",
    "    if type(text) == list:\n",
    "        l = l+1\n",
    "        print (text)\n",
    "        print(l)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "921ad47d-6899-42c5-b144-f7f27c88eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"input\"] = [\n",
    "    text[0] if isinstance(text, list) else text for text in data[\"input\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48f1f1a8-76f6-4bf7-9b80-7a6fb2a8d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"target_text\"] = [\n",
    "    text[0] if isinstance(text, list) else text for text in data[\"target_text\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48e00e27-eafc-438c-a5f9-3069e62755af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in data['input']:\n",
    "    l = 0\n",
    "    if type(text) == list:\n",
    "        print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed512d5-2ec2-49da-9d1c-5b4109b33bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data['target_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c41c748-2b5b-480a-886e-c9db64e89bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0163fdfc-44e0-4198-881a-0fbcfad1b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size = 0.2, seed =32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb711ba2-fcba-485c-b57d-374ec0a3be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_valid_split = dataset['test'].train_test_split(test_size = 0.5, seed = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "866b8719-abac-441f-830f-22ceb18afdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train' : dataset['train'],\n",
    "    'validation': test_valid_split['train'],\n",
    "    'test' : test_valid_split['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a105c15-1343-4c0f-8bfd-58d1018c33a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0576e12cc8458785c4f35ffc0a3b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f29c3db2e14599b8e94214294f7ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43622bdc80a5491fb774633b714f01ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfeab3a102b64cb88864b5eef6c76707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenize data \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccd68f24-275c-42bb-bd26-6a917f9dd060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(examples):\n",
    "    inputs = tokenizer(examples[\"input\"], max_length=512, truncation=True, padding=\"max_length\")\n",
    "    targets = tokenizer(examples[\"target_text\"], max_length=512, truncation=True, padding=\"max_length\").input_ids\n",
    "    inputs[\"labels\"] = targets\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83914865-e976-4986-ad0c-0177ba2cd2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ce7830135c4034ba511fd11d3dd2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccab45efae14542bcee25a392c30aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29aa2a8636b404392c296067af873e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply tokenization\n",
    "tokenized_dataset = dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e4eea02-d94a-4b89-aa68-d69780a74a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting absl-py\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.11/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk) (4.66.5)\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=4146ad6473aaa260e30b672663ffc3bd501a06ed3ada9f41b893f321b22d4173\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: joblib, absl-py, nltk, rouge_score\n",
      "Successfully installed absl-py-2.1.0 joblib-1.4.2 nltk-3.9.1 rouge_score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install absl-py rouge_score nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77d4cf7b-5f7a-40b9-9c03-d93149976353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88eb9522d291457e9f4575bf29acf975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load the evaluation metric: ROUGE USED TO COPARE THE MACHINE GENERATED TEXT TO ONE OR MORE REFERENCE TEXTS CREATED BY HUMANS \n",
    "#used to measure the quality og machine translation and automatic summarization software\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abb703a-5a04-4695-ae8b-022c671f31d1",
   "metadata": {},
   "source": [
    "ROUGE scores provide an evaluation of how similar the generated text is to the reference text, which serves as a measure of quality rather than strict accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba1c6c32-8782-4bea-8614-f811d6a70a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the ROUGE score \n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # Decode predictions and labels\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Compute ROUGE scores\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    result = {key: value for key, value in result.items()}  # Convert to percentage\n",
    "    \n",
    "    # Print results for each epoch\n",
    "    print(f\"Epoch evaluation result: {result}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edc17490-32a4-4900-b9e2-e04a4d765bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610cfedf26e44fa4b7d503ef64eb364d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c040c103b56042be975f3a51fe770a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4df944a056d492f8f78355d9fbfee2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize model and training arguments\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"flan-t5-cwl-finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=0.01, #edit this if necessary \n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01, #edit this if necassary \n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=30, # edit this if necessary \n",
    "    predict_with_generate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8d8d442-bfde-42fd-9af0-12197d4d6b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics  # Use the custom compute_metrics function\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f573d732-4d3f-48e5-bc2d-9cd8cc958d8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9420' max='9420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9420/9420 7:10:21, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.954929</td>\n",
       "      <td>0.018890</td>\n",
       "      <td>0.011909</td>\n",
       "      <td>0.018653</td>\n",
       "      <td>0.018731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.805600</td>\n",
       "      <td>2.511302</td>\n",
       "      <td>0.033292</td>\n",
       "      <td>0.023663</td>\n",
       "      <td>0.032907</td>\n",
       "      <td>0.032980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.805600</td>\n",
       "      <td>2.278107</td>\n",
       "      <td>0.026674</td>\n",
       "      <td>0.011755</td>\n",
       "      <td>0.026355</td>\n",
       "      <td>0.026397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.634300</td>\n",
       "      <td>2.084754</td>\n",
       "      <td>0.033292</td>\n",
       "      <td>0.023663</td>\n",
       "      <td>0.032907</td>\n",
       "      <td>0.032980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.573800</td>\n",
       "      <td>2.169274</td>\n",
       "      <td>0.074329</td>\n",
       "      <td>0.050849</td>\n",
       "      <td>0.071153</td>\n",
       "      <td>0.071164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.573800</td>\n",
       "      <td>2.139285</td>\n",
       "      <td>0.029456</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.028508</td>\n",
       "      <td>0.028468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.472400</td>\n",
       "      <td>2.316790</td>\n",
       "      <td>0.073952</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.071080</td>\n",
       "      <td>0.070999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.545800</td>\n",
       "      <td>2.237671</td>\n",
       "      <td>0.054851</td>\n",
       "      <td>0.039126</td>\n",
       "      <td>0.054141</td>\n",
       "      <td>0.054044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.545800</td>\n",
       "      <td>2.537830</td>\n",
       "      <td>0.012047</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.011948</td>\n",
       "      <td>0.012014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.775100</td>\n",
       "      <td>2.610322</td>\n",
       "      <td>0.012859</td>\n",
       "      <td>0.005913</td>\n",
       "      <td>0.012721</td>\n",
       "      <td>0.012782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.775100</td>\n",
       "      <td>2.675021</td>\n",
       "      <td>0.062483</td>\n",
       "      <td>0.044244</td>\n",
       "      <td>0.060861</td>\n",
       "      <td>0.060770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.025200</td>\n",
       "      <td>2.708486</td>\n",
       "      <td>0.007523</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.007532</td>\n",
       "      <td>0.007422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.108000</td>\n",
       "      <td>2.522208</td>\n",
       "      <td>0.020821</td>\n",
       "      <td>0.012240</td>\n",
       "      <td>0.020521</td>\n",
       "      <td>0.020491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.108000</td>\n",
       "      <td>2.498314</td>\n",
       "      <td>0.073302</td>\n",
       "      <td>0.050743</td>\n",
       "      <td>0.070215</td>\n",
       "      <td>0.070080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.905800</td>\n",
       "      <td>2.654636</td>\n",
       "      <td>0.035716</td>\n",
       "      <td>0.013778</td>\n",
       "      <td>0.035493</td>\n",
       "      <td>0.035501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.053700</td>\n",
       "      <td>2.887526</td>\n",
       "      <td>0.006122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006031</td>\n",
       "      <td>0.006042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.053700</td>\n",
       "      <td>3.127466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.163300</td>\n",
       "      <td>2.825495</td>\n",
       "      <td>0.064243</td>\n",
       "      <td>0.037612</td>\n",
       "      <td>0.063443</td>\n",
       "      <td>0.063388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.163300</td>\n",
       "      <td>2.644984</td>\n",
       "      <td>0.012859</td>\n",
       "      <td>0.005913</td>\n",
       "      <td>0.012721</td>\n",
       "      <td>0.012782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.048700</td>\n",
       "      <td>2.554277</td>\n",
       "      <td>0.063594</td>\n",
       "      <td>0.038807</td>\n",
       "      <td>0.061911</td>\n",
       "      <td>0.061885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.839800</td>\n",
       "      <td>2.489861</td>\n",
       "      <td>0.035782</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.033144</td>\n",
       "      <td>0.033053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.839800</td>\n",
       "      <td>2.471812</td>\n",
       "      <td>0.028357</td>\n",
       "      <td>0.011836</td>\n",
       "      <td>0.027979</td>\n",
       "      <td>0.028111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.723600</td>\n",
       "      <td>2.457453</td>\n",
       "      <td>0.063587</td>\n",
       "      <td>0.038807</td>\n",
       "      <td>0.062024</td>\n",
       "      <td>0.061954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.737600</td>\n",
       "      <td>2.449656</td>\n",
       "      <td>0.058884</td>\n",
       "      <td>0.035030</td>\n",
       "      <td>0.057612</td>\n",
       "      <td>0.057527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.737600</td>\n",
       "      <td>2.376489</td>\n",
       "      <td>0.068295</td>\n",
       "      <td>0.038807</td>\n",
       "      <td>0.066412</td>\n",
       "      <td>0.066392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.575600</td>\n",
       "      <td>2.354275</td>\n",
       "      <td>0.063565</td>\n",
       "      <td>0.038807</td>\n",
       "      <td>0.062306</td>\n",
       "      <td>0.062246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.575600</td>\n",
       "      <td>2.328526</td>\n",
       "      <td>0.057016</td>\n",
       "      <td>0.034271</td>\n",
       "      <td>0.055544</td>\n",
       "      <td>0.055577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.552800</td>\n",
       "      <td>2.323017</td>\n",
       "      <td>0.059275</td>\n",
       "      <td>0.035951</td>\n",
       "      <td>0.057914</td>\n",
       "      <td>0.057772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.487000</td>\n",
       "      <td>2.268126</td>\n",
       "      <td>0.020878</td>\n",
       "      <td>0.009720</td>\n",
       "      <td>0.020327</td>\n",
       "      <td>0.020476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.487000</td>\n",
       "      <td>2.253089</td>\n",
       "      <td>0.035002</td>\n",
       "      <td>0.013544</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.032247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.0188896365913186, 'rouge2': 0.011908828696967582, 'rougeL': 0.018653245485828845, 'rougeLsum': 0.01873130935458895}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.033291608137085524, 'rouge2': 0.023663437905750474, 'rougeL': 0.03290734512178008, 'rougeLsum': 0.032980360036693634}\n",
      "Epoch evaluation result: {'rouge1': 0.02667399986249242, 'rouge2': 0.011755202992751082, 'rougeL': 0.02635476786363921, 'rougeLsum': 0.026396670221694948}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.033291608137085524, 'rouge2': 0.023663437905750474, 'rougeL': 0.03290734512178008, 'rougeLsum': 0.032980360036693634}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.0743293466335791, 'rouge2': 0.05084887249752422, 'rougeL': 0.07115306785590873, 'rougeLsum': 0.071164122183766}\n",
      "Epoch evaluation result: {'rouge1': 0.029455741797633446, 'rouge2': 0.002395893557268795, 'rougeL': 0.028508385867767078, 'rougeLsum': 0.028467680662134398}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.07395190798081198, 'rouge2': 0.04977369242615561, 'rougeL': 0.07108049308831742, 'rougeLsum': 0.07099912046916151}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.0548506708339111, 'rouge2': 0.03912569593890001, 'rougeL': 0.05414102928660182, 'rougeLsum': 0.05404391767032505}\n",
      "Epoch evaluation result: {'rouge1': 0.012046798004557581, 'rouge2': 0.005261959696049225, 'rougeL': 0.011948250405401427, 'rougeLsum': 0.01201433586812313}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.012858614358714911, 'rouge2': 0.0059128091913807235, 'rougeL': 0.012720687250375248, 'rougeLsum': 0.012781877728507194}\n",
      "Epoch evaluation result: {'rouge1': 0.062482652850897887, 'rouge2': 0.04424364211064756, 'rougeL': 0.06086050984651153, 'rougeLsum': 0.060770326159128044}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.007523105411026127, 'rouge2': 0.0036340012453858596, 'rougeL': 0.00753219488571041, 'rougeLsum': 0.007422310118969435}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.020821402866488144, 'rouge2': 0.012239893509644648, 'rougeL': 0.02052139709166552, 'rougeLsum': 0.0204914988185939}\n",
      "Epoch evaluation result: {'rouge1': 0.07330231208605308, 'rouge2': 0.050742530034973886, 'rougeL': 0.07021494441316248, 'rougeLsum': 0.07008005697276423}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.03571594221568015, 'rouge2': 0.0137779534081558, 'rougeL': 0.035492911968549534, 'rougeLsum': 0.03550135103283156}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.006122482011984379, 'rouge2': 0.0, 'rougeL': 0.006031001078370341, 'rougeLsum': 0.006041622278344318}\n",
      "Epoch evaluation result: {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.06424340437047647, 'rouge2': 0.037612493286238224, 'rougeL': 0.06344271774583998, 'rougeLsum': 0.06338768587846745}\n",
      "Epoch evaluation result: {'rouge1': 0.012858614358714911, 'rouge2': 0.0059128091913807235, 'rougeL': 0.012720687250375248, 'rougeLsum': 0.012781877728507194}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.0635941921923873, 'rouge2': 0.038807378420247673, 'rougeL': 0.061911243227089865, 'rougeLsum': 0.06188474756233464}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.035781991782807276, 'rouge2': 0.014200435873547836, 'rougeL': 0.03314422672202577, 'rougeLsum': 0.03305273304218098}\n",
      "Epoch evaluation result: {'rouge1': 0.028357229055850364, 'rouge2': 0.011835838448970733, 'rougeL': 0.027979072514260808, 'rougeLsum': 0.02811092834723094}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.06358655273900526, 'rouge2': 0.038807378420247673, 'rougeL': 0.062024465091233924, 'rougeLsum': 0.061953727204272266}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.05888395123194408, 'rouge2': 0.03502962591225971, 'rougeL': 0.05761207770655527, 'rougeLsum': 0.05752685112486889}\n",
      "Epoch evaluation result: {'rouge1': 0.06829530808084971, 'rouge2': 0.038807378420247673, 'rougeL': 0.06641222640580038, 'rougeLsum': 0.06639156596069815}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.06356479789847116, 'rouge2': 0.038807378420247673, 'rougeL': 0.062305593673566737, 'rougeLsum': 0.06224649414283305}\n",
      "Epoch evaluation result: {'rouge1': 0.057016185765552625, 'rouge2': 0.03427103010163031, 'rougeL': 0.055544469233058724, 'rougeLsum': 0.055577446811298184}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.05927540889813243, 'rouge2': 0.03595063861301283, 'rougeL': 0.05791368599703513, 'rougeLsum': 0.05777200669806906}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.020877568865525564, 'rouge2': 0.009720349972548791, 'rougeL': 0.020326511179238317, 'rougeLsum': 0.0204759158533837}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluation result: {'rouge1': 0.03500184130159931, 'rouge2': 0.013543683017902798, 'rougeL': 0.03209976114509412, 'rougeLsum': 0.03224717125470521}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9420, training_loss=2.8169243166654225, metrics={'train_runtime': 25829.8704, 'train_samples_per_second': 1.459, 'train_steps_per_second': 0.365, 'total_flos': 2.580165704024064e+16, 'train_loss': 2.8169243166654225, 'epoch': 30.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6853a0b8-eddb-48d5-bbef-7ead9bf7b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"flan-t5-cwl-finetuned\")\n",
    "tokenizer.save_pretrained(\"flan-t5-cwl-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6018c700-141c-49cd-88ad-9ed55f3d65fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
