{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfdab464-0d17-429d-a16f-1b69af1568d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install scikit-learn\n",
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d88a5fa-a382-46b7-a733-ee543d88bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.2\n",
      "2.5.1+cu124\n",
      "CUDA Available: True\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3f36ede-a7bd-4400-9168-78c5dc74089b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test set...\n",
      "Predictions complete.\n",
      "Sample predictions:\n",
      "Input: transfer file from a remote FTP/HTTP server to the TES {'curl_config_file': {'type': 'File', 'inputBinding': {'prefix': '-K', 'separate': True, 'position': 1}}} {'known_sites_file': {'type': 'File', 'outputBinding': {'glob': '*.gz'}}}\n",
      "True Label: {'known_sites_file': {'type': 'File', 'outputBinding': {'glob': '*.gz'}}}\n",
      "Predicted: curl_config_file curl_config_file.input() curl_config_file.output() curl_config_file.output()\n",
      "Input: None {'illumina_accessions': 'string[]', 'ref_human_genome': 'File'} {'original_fastq1': {'type': 'File[]', 'outputSource': 'main/original_fastq1'}, 'processed_fastq': {'type': 'File', 'outputSource': 'samtools_fastq/fastq'}, 'fastqc_summary': {'type': 'File[]', 'outputSource': 'main/fastqc_summary'}, 'fastqc_zip': {'type': 'File[]', 'outputSource': 'main/fastqc_zip'}, 'multiqc_htmls': {'type': 'File[]', 'outputSource': 'main/multiqc_html'}, 'multiqc_zips': {'type': 'File[]', 'outputSource': 'main/multiqc_zip'}}\n",
      "True Label: {'original_fastq1': {'type': 'File[]', 'outputSource': 'main/original_fastq1'}, 'processed_fastq': {'type': 'File', 'outputSource': 'samtools_fastq/fastq'}, 'fastqc_summary': {'type': 'File[]', 'outputSource': 'main/fastqc_summary'}, 'fastqc_zip': {'type': 'File[]', 'outputSource': 'main/fastqc_zip'}, 'multiqc_htmls': {'type': 'File[]', 'outputSource': 'main/multiqc_html'}, 'multiqc_zips': {'type': 'File[]', 'outputSource': 'main/multiqc_zip'}}\n",
      "Predicted: 'illumina_accessions': 'string[]', 'ref_human_genome': 'File' 'original_fastq1': 'type'\n",
      "Input: Virus genome assembly with Unicycler and spades, in parallel. visualisation with bandage [{'id': 'fastq_file_type', 'type': {'type': 'enum', 'symbols': ['paired', 'single']}, 'doc': 'Paired and single end data'}, {'id': 'mode', 'type': {'type': 'enum', 'symbols': ['conservative', 'normal', 'bold']}, 'doc': 'Bridging mode, values:\\nconservative (smaller contigs, lower misassembly)\\nnormal (moderate contig size and misassembly rate)\\nbold  (longest contigs, higher misassembly rate)\\n'}, {'id': 'fastq1_type', 'type': {'type': 'enum', 'symbols': ['fastqsanger', 'fastqsanger.gz']}, 'doc': 'Type of the First set of reads. Only when fastq_file_type = single  or  paired', 'default': 'fastqsanger'}, {'id': 'fastq1', 'type': 'File', 'doc': 'First set of reads with forward reads. Only when fastq_file_type = single or paired'}, {'id': 'fastq2_type', 'type': ['null', {'type': 'enum', 'symbols': ['fastqsanger', 'fastqsanger.gz']}], 'default': 'null', 'doc': 'Type of the Second set of reads. Only when fastq_file_type=paired'}, {'id': 'fastq2', 'type': 'File?', 'doc': 'Second set of reads with reverse reads. Only when fastq_file_type=paired'}, {'id': 'libraries_metadata', 'type': {'type': 'array', 'items': {'type': 'record', 'fields': [{'name': 'lib_index', 'type': 'int?'}, {'name': 'orientation', 'type': 'string?'}, {'name': 'lib_type', 'type': 'string?'}]}}, 'doc': 'reads library metadata\\nrelated to   libraries_fwd_rev and libraries_mono inputs\\nlib_index(id) must match\\n'}, {'id': 'libraries_fwd_rev', 'type': {'type': 'array', 'items': {'type': 'record', 'fields': [{'name': 'lib_index', 'type': 'int?'}, {'name': 'fwd_reads', 'type': 'File?'}, {'name': 'rev_reads', 'type': 'File?'}]}}, 'doc': 'reads file\\norientation must be a value in  ff, fr, rf\\nK-mer choices can be chosen by SPAdes instead of being entered manually\\n'}, {'id': 'libraries_mono', 'type': {'type': 'array', 'items': {'type': 'record', 'fields': [{'name': 'lib_index', 'type': 'int?'}, {'name': 'file_type', 'type': 'string?'}, {'name': 'reads', 'type': 'File?'}]}}, 'doc': 'reads file\\nfile_type value must be in : interleaved, merged, unpaired\\n'}, {'id': 'pacbio_reads', 'type': ['null', {'type': 'array', 'items': 'File'}]}, {'id': 'nanopore_reads', 'type': ['null', {'type': 'array', 'items': 'File'}]}, {'id': 'sanger_reads', 'type': ['null', {'type': 'array', 'items': 'File'}]}, {'id': 'trusted_contigs', 'type': ['null', {'type': 'array', 'items': 'File'}]}, {'id': 'untrusted_contigs', 'type': ['null', {'type': 'array', 'items': 'File'}]}, {'id': 'auto_kmer_choice', 'type': 'boolean', 'default': True, 'doc': 'Automatically choose k-mer values.\\nK-mer choices can be chosen by SPAdes instead of being entered manually\\n'}, {'id': 'kmers', 'type': 'string', 'default': '21,33,55', 'doc': 'K-mers to use, separated by commas.\\nComma-separated list of k-mer sizes to be used \\n(all values must be odd, less than 128, listed in ascending order,\\n and smaller than the read length). The default value is 21,33,55\\n'}, {'id': 'cov_state', 'type': ['null', {'type': 'enum', 'symbols': [False, 'value', 'auto']}], 'doc': \"Coverage cutoff ( 'auto', or 'off', or 'value'). auto if null\\nwhen cov_state=value (User Specific) , cov_cutoff must be provided\\n\"}, {'id': 'cov_cutoff', 'type': 'float?', 'doc': 'coverage cutoff value (a positive float number )\\n'}, {'id': 'iontorrent', 'type': 'boolean', 'default': False, 'doc': 'true if Libraries are IonTorrent reads.\\n'}, {'id': 'sc', 'type': 'boolean', 'default': False, 'doc': 'This option is required for MDA. \\ntrue if single-cell data. \\n'}, {'id': 'onlyassembler', 'type': 'boolean', 'default': False, 'doc': 'Run only assembly if true\\n(without read error correction)\\n'}, {'id': 'careful', 'type': 'boolean', 'default': True, 'doc': 'Careful correction.\\nTries to reduce number of mismatches and short indels. \\nAlso runs MismatchCorrector, a post processing tool,\\nwhich uses BWA tool (comes with SPAdes).\\n'}] [{'id': 'out_contigs_spades', 'outputSource': ['spades/out_contigs'], 'type': 'File'}, {'id': 'out_scaffolds_spades', 'outputSource': ['spades/out_scaffolds'], 'type': 'File'}, {'id': 'out_contig_stats_spades', 'outputSource': ['spades/out_contig_stats'], 'type': 'File'}, {'id': 'out_scaffold_stats_spades', 'outputSource': ['spades/out_scaffold_stats'], 'type': 'File'}, {'id': 'assembly_graph_spades', 'outputSource': ['spades/assembly_graph'], 'type': 'File'}, {'id': 'assembly_graph_with_scaffolds_spades', 'outputSource': ['spades/assembly_graph_with_scaffolds'], 'type': 'File'}, {'id': 'all_log_spades', 'outputSource': ['spades/all_log'], 'type': 'File[]'}, {'id': 'assembly_image_spades', 'outputSource': ['bandage_image_spades/image'], 'type': 'File'}, {'id': 'assembly_info_spades', 'outputSource': ['bandage_info_spades/assembly_graph_info'], 'type': 'File'}, {'id': 'assembly_graph_unicycler', 'outputSource': ['unicycler/assembly_graph'], 'type': 'File'}, {'id': 'assembly_unicycler', 'outputSource': ['unicycler/assembly'], 'type': 'File'}, {'id': 'assembly_image_unicycler', 'outputSource': ['bandage_image_unicycler/image'], 'type': 'File'}, {'id': 'assembly_info_unicycler', 'outputSource': ['bandage_info_unicycler/assembly_graph_info'], 'type': 'File'}]\n",
      "True Label: [{'id': 'out_contigs_spades', 'outputSource': ['spades/out_contigs'], 'type': 'File'}, {'id': 'out_scaffolds_spades', 'outputSource': ['spades/out_scaffolds'], 'type': 'File'}, {'id': 'out_contig_stats_spades', 'outputSource': ['spades/out_contig_stats'], 'type': 'File'}, {'id': 'out_scaffold_stats_spades', 'outputSource': ['spades/out_scaffold_stats'], 'type': 'File'}, {'id': 'assembly_graph_spades', 'outputSource': ['spades/assembly_graph'], 'type': 'File'}, {'id': 'assembly_graph_with_scaffolds_spades', 'outputSource': ['spades/assembly_graph_with_scaffolds'], 'type': 'File'}, {'id': 'all_log_spades', 'outputSource': ['spades/all_log'], 'type': 'File[]'}, {'id': 'assembly_image_spades', 'outputSource': ['bandage_image_spades/image'], 'type': 'File'}, {'id': 'assembly_info_spades', 'outputSource': ['bandage_info_spades/assembly_graph_info'], 'type': 'File'}, {'id': 'assembly_graph_unicycler', 'outputSource': ['unicycler/assembly_graph'], 'type': 'File'}, {'id': 'assembly_unicycler', 'outputSource': ['unicycler/assembly'], 'type': 'File'}, {'id': 'assembly_image_unicycler', 'outputSource': ['bandage_image_unicycler/image'], 'type': 'File'}, {'id': 'assembly_info_unicycler', 'outputSource': ['bandage_info_unicycler/assembly_graph_info'], 'type': 'File'}]\n",
      "Predicted: ['id': 'fastq1_type', 'type': 'enum', 'symbols': 'fastqsanger', 'fastq\n",
      "Input: None [{'id': 'input', 'type': ['File', {'type': 'array', 'items': 'File'}], 'inputBinding': {'position': 2, 'prefix': '-I'}}, {'id': 'rtc_intervals', 'type': 'File', 'inputBinding': {'position': 3, 'prefix': '-targetIntervals'}}, {'id': 'reference_genome', 'type': 'File', 'inputBinding': {'position': 1, 'prefix': '-R'}}, {'id': 'realigned_bam_name', 'type': 'File?', 'inputBinding': {'position': 3, 'prefix': '-O'}}] [{'id': 'realigned_bam', 'type': 'File', 'secondaryFiles': ['^.bai']}]\n",
      "True Label: [{'id': 'realigned_bam', 'type': 'File', 'secondaryFiles': ['^.bai']}]\n",
      "Predicted: ['id': 'input', 'type': 'File', 'items': 'File', 'inputBinding':\n",
      "Input: CWL version of the md_list.cwl workflow for HPC. This performs a system setup and runs a molecular dynamics simulation on the structure passed to this workflow. This workflow uses the md_gather.cwl sub-workflow to gather the outputs together to return these.\n",
      "To work with more than one structure this workflow can be called from either the md_launch.cwl workflow, or the md_launch_mutate.cwl workflow. These use scatter for parallelising the workflow. md_launch.cwl operates on a list of individual input molecule files. md_launch_mutate.cwl operates on a single input molecule file, and a list of mutations to apply to that molecule. Within that list of mutations, a value of 'WT' will indicate that the molecule should be simulated without any mutation being applied.\n",
      " {'step1_pdb_file': {'label': 'Input file', 'doc': 'Molecule to process (PDB format)', 'type': 'File'}, 'step2_editconf_config': {'label': 'Editconf configuration dictionary', 'type': 'string'}, 'step4_grompp_genion_config': {'label': 'GROMACS grompp configuration dictionary', 'type': 'string'}, 'step5_genion_config': {'label': 'Genion configuration dictionary', 'type': 'string'}, 'step6_grompp_min_config': {'label': 'GROMACS grompp configuration dictionary', 'type': 'string'}, 'step8_make_ndx_config': {'label': 'GROMACS make_ndx configuration dictionary', 'type': 'string'}, 'step9_grompp_nvt_config': {'label': 'GROMACS grompp configuration dictionary', 'type': 'string'}, 'step11_grompp_npt_config': {'label': 'GROMACS grompp configuration dictionary', 'type': 'string'}, 'step13_grompp_md_config': {'label': 'GROMACS grompp configuration dictionary', 'type': 'string'}, 'step14_mdrun_md_config': {'label': 'GROMACS mdrun configuration dictionary', 'type': 'string'}} {'dir': {'label': 'whole workflow output', 'doc': 'outputs from the whole workflow, containing these optional files:\\nstep14_mdrun_md/output_trr_file:   Raw trajectory from the free simulation step\\nstep14_mdrun_md/output_gro_file:   Raw structure from the free simulation step.\\nstep14_mdrun_md/output_cpt_file:   GROMACS portable checkpoint file, allowing to restore (continue) the\\n                                   simulation from the last step of the setup process.\\nstep13_grompp_md/output_tpr_file:  GROMACS portable binary run input file, containing the starting structure\\n                                   of the simulation, the molecular topology and all the simulation parameters.\\nstep5_genion/output_top_zip_file:  GROMACS topology file, containing the molecular topology in an ASCII\\n                                   readable format.\\n', 'type': 'Directory', 'outputSource': 'step15_gather_outputs/project_work_dir'}}\n",
      "True Label: {'dir': {'label': 'whole workflow output', 'doc': 'outputs from the whole workflow, containing these optional files:\\nstep14_mdrun_md/output_trr_file:   Raw trajectory from the free simulation step\\nstep14_mdrun_md/output_gro_file:   Raw structure from the free simulation step.\\nstep14_mdrun_md/output_cpt_file:   GROMACS portable checkpoint file, allowing to restore (continue) the\\n                                   simulation from the last step of the setup process.\\nstep13_grompp_md/output_tpr_file:  GROMACS portable binary run input file, containing the starting structure\\n                                   of the simulation, the molecular topology and all the simulation parameters.\\nstep5_genion/output_top_zip_file:  GROMACS topology file, containing the molecular topology in an ASCII\\n                                   readable format.\\n', 'type': 'Directory', 'outputSource': 'step15_gather_outputs/project_work_dir'}}\n",
      "Predicted: 'step1_pdb_file': 'label': 'Input file', 'doc': 'Molecule to process (PDB format)',\n",
      "Model Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "# Load the data from the GitHub link\n",
    "github_url = \"https://raw.githubusercontent.com/gracwng/LLM-Bioinformatic-Pipeline-Generation/refs/heads/main/cwl_documents/workflowhub/transformed_data/transformed_workflow_cwl_documents.json\"\n",
    "response = requests.get(github_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        data = response.json()\n",
    "    except ValueError as e:\n",
    "        raise Exception(f\"Error parsing JSON: {e}\\nResponse text: {response.text[:500]}\")\n",
    "else:\n",
    "    raise Exception(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "\n",
    "# Convert JSON data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check if required fields exist\n",
    "required_columns = ['description', 'inputs', 'outputs']\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "if missing_columns:\n",
    "    raise Exception(f\"Missing required columns: {missing_columns}\")\n",
    "\n",
    "# Extract features and labels\n",
    "df['features'] = df[['description', 'inputs', 'outputs']].apply(lambda x: ' '.join(map(str, x)), axis=1)\n",
    "df['label'] = df['outputs']\n",
    "\n",
    "# Drop rows with missing or invalid labels\n",
    "df = df[df['label'].notnull()]\n",
    "\n",
    "# Ensure labels are discrete classes (convert to string for classification)\n",
    "df['label'] = df['label'].astype(str)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df['features']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load the Alpaca model and tokenizer\n",
    "model_name = \"declare-lab/flan-alpaca-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Function to predict using the Alpaca model\n",
    "def alpaca_predict(input_texts):\n",
    "    inputs = tokenizer(input_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model.generate(**inputs, max_length=50)\n",
    "    predictions = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    # Clean up predictions\n",
    "    return [pred.strip().split('\\n')[0] for pred in predictions]\n",
    "\n",
    "# Predict on the test set\n",
    "print(\"Predicting on test set...\")\n",
    "test_predictions = alpaca_predict(X_test.tolist())\n",
    "print(\"Predictions complete.\")\n",
    "\n",
    "# Debug: Inspect predictions and true labels\n",
    "print(\"Sample predictions:\")\n",
    "for input_text, true_label, prediction in zip(X_test[:5], y_test[:5], test_predictions[:5]):\n",
    "    print(f\"Input: {input_text}\")\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted: {prediction}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = sum(\n",
    "    1 for true, pred in zip(y_test, test_predictions)\n",
    "    if true.strip().lower() in pred.strip().lower()  # Case-insensitive substring match\n",
    ")\n",
    "total_predictions = len(y_test)\n",
    "accuracy_percentage = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca0460-6fe8-4f16-b274-aa2906a4ac33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
